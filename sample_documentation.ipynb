{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Location.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the output RDF file revealed that some prefixes were not used.\n",
    "These prefixes were: _geonames_ and _wgs84_pos_.\n",
    "Having ascertained the lack of a script dedicated to the creation of information linked to geographical places, it was decided to proceed with the creation of the same to finalize the RDF file.\n",
    "\n",
    "The desired output for RDF enrichment is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "<https://w3id.org/moro/enoam/data/alessandria> a dcterms:Location ;\n",
    "    rdfs:label \"Alessandria\"^^xsd:string ;\n",
    "    geonames:featureClass geonames:P ;\n",
    "    owl:sameAs <http://www.wikidata.org/entity/Q6088> ;\n",
    "    wgs84_pos:lat \"44.90924\" ;\n",
    "    wgs84_pos:long \"8.61007\" . \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import some libraries:\n",
    "\n",
    "_urllib.parse_: This module provides functions to manipulate URLs and their components.\n",
    "\n",
    "_requests_: This library is used for making HTTP requests in Python.\n",
    "\n",
    "_os_: This is a standard library module in Python used for interacting with the operating system. It provides functions for interacting with the filesystem, managing environment variables, and executing system commands.\n",
    "\n",
    "_json_: This is used for working with JSON (JavaScript Object Notation) data.\n",
    "\n",
    "_re_: This is used for working with regular expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_location(location):\n",
    "    if not location:  # Check for empty input\n",
    "        return None\n",
    "    \n",
    "    normalized_location = location.lower().strip()\n",
    "    \n",
    "    # Skip inputs with less than 4 letters\n",
    "    if len(normalized_location) < 4:\n",
    "        return None\n",
    "    else:\n",
    "        if ',' in normalized_location: # Manage cases like \"Roma, Italia\"\n",
    "            normalized_location = normalized_location.split(',')[0]\n",
    "\n",
    "        # Remove parentheses and text within parentheses like in \"Roma (Italia)\"\n",
    "        normalized_location = re.sub(r'\\([^)]*\\)', '', normalized_location)\n",
    "\n",
    "        normalized_location = normalized_location.strip()\n",
    "\n",
    "        return normalized_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function follows these steps:\n",
    "\n",
    "   1. It checks if the input location string is empty. If empty, returns None. \n",
    "    \n",
    "   2. If there is an input,  it converts the input location string to lowercase and removes leading and trailing whitespace. \n",
    "\n",
    "   3. Skips normalization for input strings with less than 4 characters. If the input has less than 4 characters, it's considered too short and returns None. \n",
    "\n",
    "   4. If the location contains a comma (,), it removes everything after the comma, considering it as a subregion. For example, in \"Roma, Italia\", it keeps only \"Roma\". \n",
    "\n",
    "   5. Removes text enclosed in parentheses, including the parentheses themselves. This is useful for cases like \"Roma (Italia)\", where it removes \"(Italia)\" and keeps only \"Roma\". \n",
    "\n",
    "   6. Strips leading and trailing whitespace again after all modifications. \n",
    "\n",
    "   7. Returns the normalized location string. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(location):\n",
    "    json_file_path = 'geonames_data.json' # Create an empty json file for storing data\n",
    "\n",
    "    print(location) # Check the running of the code while running \"main.py\"\n",
    "\n",
    "    if os.path.exists(json_file_path): # If the file already exist open it\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    else:\n",
    "        json_data = {}\n",
    "\n",
    "    with open('errori.json', 'r') as error_file: # Open the file where the errors will be stored\n",
    "        errori_location = json.load(error_file)\n",
    "\n",
    "    clean_location = normalize_location(location) # Call normalize_location\n",
    "    \n",
    "    if not clean_location:  # Check for invalid or empty location\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Checks if a JSON file containing cached data exists. If it does, loads the data.\n",
    "2. If the JSON file doesn't exist, initializes an empty dictionary for storing data.\n",
    "3. Opens a separate JSON file for storing error data.\n",
    "4. Calls the _normalize_location_ function to clean and normalize the input location string.\n",
    "5. Checks for invalid or empty location. If found, returns None.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clean_location in json_data: # Check if the location is already stored in the json file \"geonames_data\" \n",
    "        existing_data = json_data[clean_location]\n",
    "        return existing_data\n",
    "    elif clean_location in errori_location: # Check if the location is already stored in \"errori\"\n",
    "        return False\n",
    "    else:\n",
    "        # Set your GeoNames username\n",
    "        username = 'aldomorodigitale'\n",
    "\n",
    "        # Define parameters for the call\n",
    "        parametri = {'q': clean_location, 'maxRows': 10, 'username': username}\n",
    "\n",
    "        # Encode parameters\n",
    "        location_encode = urllib.parse.urlencode(parametri)\n",
    "\n",
    "        # Construct GeoNames API URL\n",
    "        url = 'http://api.geonames.org/searchJSON?' + location_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checks if the normalized location is already stored in the cached data. If found, returns the stored coordinates.\n",
    "7. Checks if the normalized location is already marked as an error. If found, returns False.\n",
    "8. If the location is not cached or marked as an error, proceeds to make an API call to _GeoNames_.\n",
    "9. Sets the _GeoNames_ username and defines parameters for the API call.\n",
    "10. Encodes the parameters for the URL.\n",
    "11. Constructs the GeoNames API URL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "            # Send GET request\n",
    "            resp = requests.get(url)\n",
    "            resp.raise_for_status()  # Raise HTTPError for non-200 status codes\n",
    "            \n",
    "            # Parse JSON response\n",
    "            data = resp.json()\n",
    "\n",
    "            for item in data[\"geonames\"]:\n",
    "                if item['fcl'] in ('L', 'A', 'P', 'H'):  # Check the feature class\n",
    "                    if item['fcl'] == 'H':\n",
    "                        item['fcl'] = 'A'\n",
    "                    result = item\n",
    "                    break\n",
    "\n",
    "            if result and clean_location != \"null\": # Create variables of the results \n",
    "                latitude = str(result['lat'])\n",
    "                longitude = str(result['lng'])\n",
    "                address_type = str(result['fcl'])\n",
    "                countryCode = str(result.get('countryCode'))\n",
    "                toponymName = str(result['toponymName'])\n",
    "\n",
    "                json_data[clean_location] = [longitude, latitude, address_type, countryCode, toponymName]\n",
    "\n",
    "                with open(json_file_path, 'w') as json_file: # Store results in \"geonames_data\"\n",
    "                    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "                return json_data[clean_location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Sends a GET request to the GeoNames API.\n",
    "13. Parses the JSON response.\n",
    "14. Iterates through the response data to find the most relevant result based on feature class. The selected feature class are these utilized for the correct functioning of the interactive map in the website. Every class correspond to a specific zoom measure and point color.\n",
    "15. If a relevant result is found and the location is not 'null', extracts relevant information and store them as strings.\n",
    "16. Stores the retrieved data in the cached data JSON file.\n",
    "17. Returns the retrieved coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " else: \n",
    "                with open('errori.json', 'w') as error_file:\n",
    "                    errori_location[clean_location] = [\"1\"]\n",
    "                    json.dump(errori_location, error_file)\n",
    "                print(\"------------------- \" + location)\n",
    "                return False\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error occurred during API request:\", e)\n",
    "            return None\n",
    "        except KeyError:\n",
    "            print(\"Invalid or unexpected API response format.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. If no relevant result is found or the location is 'null', marks the location as an error and returns False. Also print the name of the error location to check it during the script processing.\n",
    "19. Handles exceptions for HTTP request errors and unexpected API response formats, printing error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final creation of the triples with all this new information in the RDF file, we are going to insert some portions of code into the _generate_ and _align_ scripts. \n",
    "\n",
    "_Generate_ processes the metadata deriving from _kwickwockwac_ and transforms them into triples. Some locations are found here, those related to the place where the document was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from datetime import datetime\n",
    "from rdflib import URIRef, Namespace, Literal\n",
    "from rdflib.namespace import RDF, RDFS, DCTERMS, FOAF, XSD, SKOS, OWL\n",
    "from lib.location3 import get_coordinates, normalize_location\n",
    "import os\n",
    "\n",
    "# ...\n",
    "\n",
    "# ADD SPATIAL COVERAGE\n",
    "def add_spatial(g, value, expression, dataset_ns):\n",
    "\n",
    "    geonames = Namespace('http://www.geonames.org/ontology#')\n",
    "    wgs84_pos = Namespace('http://www.w3.org/2003/01/geo/wgs84_pos#')\n",
    "    g.bind('geonames', geonames)\n",
    "    g.bind('wgs84_pos', wgs84_pos)\n",
    "\n",
    "    place_text = value.lower()\n",
    "    place = URIRef(f'{dataset_ns}{value.replace(\" \", \"-\").lower()}')\n",
    "    g.add((place, RDF.type, DCTERMS.Location))\n",
    "    g.add((place, RDFS.label, Literal(value, datatype=XSD.string)))\n",
    "    g.add((expression, DCTERMS.spatial, place))\n",
    "\n",
    "    if place:\n",
    "\n",
    "        normalize = normalize_location(place_text)\n",
    "        coordinates = get_coordinates(normalize)\n",
    "\n",
    "        if coordinates:\n",
    "            \n",
    "\n",
    "            long = coordinates[0]\n",
    "            lat = coordinates[1]\n",
    "            key = coordinates[2]\n",
    "        \n",
    "            g.add((place, wgs84_pos.lat, Literal(lat)))\n",
    "            g.add((place, wgs84_pos.long, Literal(long)))\n",
    "            g.add((place, geonames.featureClass, geonames[key]))\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Align_ processes the data present in each html and aligns them with the related metadata. \n",
    "In this script all the locations mentioned in the documents and which have been marked by the researchers as relevant are selected. In this way the final map shows all the locations mentioned by Aldo Moro, the number of recursions and links to the related documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import rdflib\n",
    "from rdflib import URIRef, Namespace, Literal\n",
    "from rdflib.namespace import RDF, RDFS, DCTERMS, FOAF, XSD, SKOS, OWL\n",
    "from lib.location3 import get_coordinates, normalize_location\n",
    "\n",
    "#ADD GEONAMES\n",
    "            \n",
    "    \n",
    "    # Trovare tutti gli elementi <span> con la classe \"mention place\"\n",
    "    mention_places = soup.find_all('span', class_='mention place')\n",
    "\n",
    "    # print(mention_places)\n",
    "\n",
    "    # Verifica se la lista mention_places non è vuota\n",
    "    if mention_places and mention_places != None:\n",
    "        # Iterare sugli elementi trovati\n",
    "        for mention_place in mention_places:\n",
    "            # Ottenere il testo all'interno dell'elemento\n",
    "            place_text = mention_place.get_text()\n",
    "            # print(place_text)\n",
    "    \n",
    "        \n",
    "            coordinates = get_coordinates(place_text)\n",
    "\n",
    "            # print(coordinates)\n",
    "\n",
    "            if coordinates:\n",
    "                # Ottenere l'attributo \"resource\" se presente\n",
    "                resource_attribute_uri = mention_place.get('resource')\n",
    "\n",
    "                # Ensure that resource_attribute is a URIRef\n",
    "                resource_attribute = URIRef(resource_attribute_uri)\n",
    "\n",
    "                long = coordinates[0]\n",
    "                lat = coordinates[1]\n",
    "                key = coordinates[2]\n",
    "            \n",
    "                g.add((resource_attribute, wgs84_pos.lat, Literal(lat)))\n",
    "                g.add((resource_attribute, wgs84_pos.long, Literal(long)))\n",
    "                g.add((resource_attribute, geonames.featureClass, geonames[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
